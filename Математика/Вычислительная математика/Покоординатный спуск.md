#Вычислительная_математика 

Метод покоординатного спуска есть метод минимизации функций нескольких переменных, когда мы задаем константное значение для всех переменных кроме одной и минимизируем значение функции как функцию одной переменной.

Допустим у нас есть некоторая функция $f(\mathbf{x})$
Зададимся некоторым вектором $\mathbf{v}_{n}$ который в данном методе принимает вид $\{0, 0,\dots,v,\dots,0\}$

Тогда имеем: $\mathbf{x}_{n+1}=\mathbf{x}_{n}+h\mathbf{v}_{n}$

Вектор $\mathbf{v}_{n}$ выбирается не произвольно, он должен быть направлен в противоположную сторону от градиента выбранного компонента вектора $\mathbf{x}$

После того как был достигнут минимум по выбранной компоненте 
$$f(x^{(1)},\dots,x^{(k)}_{n-1},\dots,x^{(m)})<f(x^{(1)},\dots,x^{(k)}_{n},\dots,x^{(m)})>f(x^{(1)},\dots,x^{(k)}_{n+1},\dots,x^{(m)})$$
выбирается следующая. 

![[Pasted image 20220525164500.png]]

Однако при плохо обусловленных функциях метод покоординатного спуска сильно теряет в скорости, приходится выполнять множество мелких шагов.

![[Pasted image 20220526143248.png]]