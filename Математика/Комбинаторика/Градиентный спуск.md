#Вычислительная_математика 

Градиентный спуск - метод нахождения минимума функции нескольких переменных.

Допустим у нас есть функция $f(\mathbf{x})$, задаваемая вектором $\mathbf{x}$. 

Мы вычисляем для нее вектор $\mathbf{v}$ для следующего преобразования:

$$\mathbf{x}_{n+1}=\mathbf{x}_{n}+h\mathbf{v}_{n}$$

Требуется, чтобы мы пришли к следующему условию:

$$f(\mathbf{x}_{n-1})<f(\mathbf{x}_{n})>f(\mathbf{x}_{n+1})$$

В методе градиентного спуска таким вектором $\mathbf{v}$ является непосредственно анти-[[Градиент|градиент]].

$$\mathbf{v}=-grad\Big(\frac{\partial f}{\partial x^{(1)}},\dots,\frac{\partial f}{\partial x^{(m)}}\Big)$$

А коэффициент $h$ отвечает за длинну проделанного шага.

![[Pasted image 20220525170103.png]]

Однако при плохо обусловленной функции метод градиентного спуска сильно теряет в скорости, тк приходится выполнять большое количество итераций с маленькими изменениями.

![[Pasted image 20220526143748.png]]



