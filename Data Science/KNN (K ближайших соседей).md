#Data_Science 

KNN (Key-Nearest Neighbors) является простым алгоритмом, который предсказывает признак по его ближайшим соседям. Основным параметром алгоритма является количество ближайших соседей.

Данный алгоритм может использоваться для задач [[Multilabel classification|классификации]] и [[Регрессия|регрессии]].

Основная идея заключается в том что
- Для задач регрессии алгоритм берет среднее (арифметическое или взвешенное) по ближайшим по метрике соседям и выдает соответствующий результат.
- Для задач классификации алгоритм берет тот класс, который чаще встречается.
![[Pasted image 20220822140911.png]]

## Минусы KNN
Так как основной идеей является нахождения ближайших соседей по норме пространства $\mathbf{R}^{n}$ основной проблемой является кучность объектов между собой с увеличением $n$ 

![[Pasted image 20220822145622.png]]
Соответственно, наше предположение, что близкие точки имеют одинаковый ответ становится все дальше и дальше от действительности.

Так же для KNN актуальна проблема масштаба. Однако ее можно решить [[Стандартизация данных|нормализацией данных]] перед использованием в модели

Реализацией данного алгоритма в библиотеке [[Scipy]] является класс [NearestNeighbors](https://scikit-learn.org/stable/modules/neighbors.html). По ссылке доступна вся нужная документация.